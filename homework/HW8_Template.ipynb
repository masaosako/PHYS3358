{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ab7ed62",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14b9963875f2ccce206997f11dc8ffcd",
     "grade": false,
     "grade_id": "cell-1e3a839177d28bb8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Problem 1**\n",
    "\n",
    "**CODING:** This is a continuation of HW7 where you will learn how to perform non-linear regression and also see how more data improves the statistical quality of the data and the resulting parameter constraints.  There are 10 data files `run[0-9].dat` that contain hypothetical particle-physics spectral data (energy vs counts) of a search for a new particle called the *Riggs boson*.  The data were taken independently in 10 distinct runs.  The columns are 1) energy $E$ (GeV) and 2) counts $N$ (number of events in that energy bin).\n",
    "  \n",
    "       1.0    96\n",
    "       2.0    99\n",
    "       3.0   111\n",
    "       4.0   124\n",
    "       5.0   105\n",
    "       6.0   102\n",
    "       ...\n",
    "\n",
    "  \n",
    "  A signal of a new particle consists of a gaussian on top of a smooth background.  Model the spectrum with a function given by:\n",
    "$$\n",
    "  N(E) = a + bE +cE^2 + Ae^{-(E-E_{\\mathrm{Riggs}})^2/(2\\sigma_E^2)}\n",
    "$$\n",
    "where we now have 6 fit parameters -- $a,b,c,A,E_{\\mathrm{Riggs}},\\sigma_E$.  The first three terms make up the background, the last term represents the signal.  We assume here that $\\sigma_E$ and $E_{\\mathrm{Riggs}}$ are unknown, but they are expected to be in the range 1 - 5 GeV and 40 - 90 GeV, respectively.\n",
    "\n",
    "a) (4 pts) In this first part, use only the first data file `run0.dat`.  Use `scipy.optimize.curve_fit` to determine the best-fit values of the parameters and the covariance matrix.  Can you claim a detection of the Riggs boson?  Justify your answer.\n",
    "\n",
    "b) (3 pts) Since the 10 datasets are independent, the counts can simply be added to produce a dataset with higher statistical quality.  Successively add the counts in `run1.dat`, `run2.dat`, and so on and repeat the fits.  After which run can you claim a $5\\sigma$ detection of the Riggs?\n",
    "\n",
    "c) (3 pts) Using data from all 10 runs, measure the energy $E_{\\mathrm{Riggs}}$ and uncertainty of the the Riggs boson.  What is the final significance (in units of $\\sigma$) of the detection?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feee4c08",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca2e8974aa7c7c4ac2a79adc336b97d2",
     "grade": false,
     "grade_id": "cell-e9aa02daaf35d396",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize\n",
    "\n",
    "# Problem 1a\n",
    "def read_riggs_data(n):\n",
    "    \"\"\"\n",
    "    Read the data file for run n, where 0 <= n <= 9.\n",
    "    \n",
    "    The file name is run[n].dat.  (I.e. run0.dat, run1.dat, ... run9.dat)\n",
    "    \n",
    "    Returns E, N for this run as numpy arrays\n",
    "    \"\"\"\n",
    "    # Hint: If you use pandas to read the file, to_numpy() will convert to a numpy array\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def riggs_model(E, a, b, c, A, E_Riggs, sigma_E):\n",
    "    \"\"\"\n",
    "    Return the expected counts given the model for the Riggs boson.\n",
    "    \n",
    "        N(E) = a + b E + c E**2 + A exp(-(E-E_Riggs)**2/(2 sigma_E**2))\n",
    "    \n",
    "    On input, E is an array.  The other parameters are scalars.\n",
    "    \n",
    "    Returns N(E) given the model parameters.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def fit_riggs_model(E, N):\n",
    "    \"\"\"\n",
    "    Find the best fit model given the observed data N(E)\n",
    "\n",
    "    Returns the parameters [a, b, c, A, E_Riggs, sigma_E] as a numpy array \n",
    "    and the covariance matrix, also as a numpy array.\n",
    "    \"\"\"\n",
    "    # Hints:\n",
    "    # 1. Use scipy.optimize.curve_fit\n",
    "    # 2. Make sure to set the uncertainties correctly based on Poisson errors (sigma_N = sqrt(N))\n",
    "    # 3. Set the bounds appropriately for E_Riggs and sigma_E based on the problem statement.\n",
    "    # 4. For the amplitude, we know it's positive, so [0,1.e10] is appropriate.\n",
    "    # 5. For the first three [-1.e10,1.e10] is fine. (i.e. basically no prior information, although\n",
    "    #    it is helpful to put some kind of upper bounds other than infinity).\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def calculate_significance(params, cov):\n",
    "    \"\"\"\n",
    "    Calculate the significance of a possible detection of the Riggs boson.\n",
    "    \n",
    "    params = [a, b, c, A, E_Riggs, sigma_E]\n",
    "    cov = the estimated covariance matrix\n",
    "    \n",
    "    Returns the S/N of the purported detection.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def calculate_energy(params, cov):\n",
    "    \"\"\"\n",
    "    Calculate the estimated value of E_Riggs and its uncertainty.\n",
    "\n",
    "    params = [a, b, c, A, E_Riggs, sigma_E]\n",
    "    cov = the estimated covariance matrix\n",
    "    \n",
    "    Returns the estimate of (E_Riggs, sigma(E_Riggs)).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8625b72b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "095c55685cdecf673ec172ab445131e6",
     "grade": true,
     "grade_id": "cell-0dcecef09a7cd732",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "E, N = read_riggs_data(0)\n",
    "\n",
    "params, cov = fit_riggs_model(E,N)\n",
    "\n",
    "print('params = ',params)\n",
    "print('sigma = ',np.sqrt(np.diag(cov)))\n",
    "print('Significance = ',calculate_significance(params, cov))\n",
    "\n",
    "# Quick and dirty visualization of the data and the fit\n",
    "fig, ax = plt.subplots(1,1, figsize=(14,8))\n",
    "ax.plot(E,N)\n",
    "ax.plot(E,riggs_model(E,*params))\n",
    "ax.set_xlabel('E')\n",
    "ax.set_ylabel('N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4c5807",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dfe3841d714a55bb3d46ca6f33577d95",
     "grade": true,
     "grade_id": "cell-4bce5209d816642f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "(Problem 1a) \n",
    "\n",
    "Can you claim a detection of the Riggs boson?  Justify your answer.\n",
    "\n",
    "----\n",
    "\n",
    "YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d9ed6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2eefeb5c600e9a934ed5c097f79938a9",
     "grade": false,
     "grade_id": "cell-30f9162ffbb4ccc1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(14,8))\n",
    "\n",
    "E, N = read_riggs_data(0)\n",
    "params, cov = fit_riggs_model(E,N)\n",
    "nu = calculate_significance(params, cov)\n",
    "E_R, sig = calculate_energy(params, cov)\n",
    "print('i=0: nu = {}, E = {} +- {}'.format(nu,E_R,sig))\n",
    "\n",
    "for i in range(1,10):\n",
    "    #print('N  = ',N)\n",
    "    Ei, Ni = read_riggs_data(i)\n",
    "    #print('Ni = ',Ni)\n",
    "    assert np.allclose(E,Ei)\n",
    "    N += Ni\n",
    "\n",
    "    params, cov = fit_riggs_model(E,N)\n",
    "    nu = calculate_significance(params, cov)\n",
    "    E_R, sig = calculate_energy(params, cov)\n",
    "    print('i={}: nu = {}, E = {} +- {}'.format(i,nu,E_R,sig))\n",
    "\n",
    "    ax.plot(E,N)\n",
    "    ax.plot(E,riggs_model(E,*params))\n",
    "\n",
    "ax.set_xlabel('E')\n",
    "ax.set_ylabel('N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642f42c3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38b6b3e7615aafa4852b1e3de3345cbf",
     "grade": true,
     "grade_id": "cell-a29e6144b4c98700",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "(Problem 1b) \n",
    "\n",
    "After which run can you claim a 5 sigma detection of the Riggs?\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce818694",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f04d31208f6442d7b668f9c31e3ba66",
     "grade": true,
     "grade_id": "cell-6f76f7f3303d1634",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "(Problem 1c) \n",
    "\n",
    "Using data from all 10 runs, measure the energy E_Riggs and uncertainty of the the Riggs boson. \n",
    "\n",
    "YOUR ANSWER HERE\n",
    "\n",
    "----\n",
    "\n",
    "What is the final significance of the detection?\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323e7433",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a13fd586eb1d8151a63ce713b76afa8b",
     "grade": false,
     "grade_id": "cell-f2d05ccb09bd9348",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Problem 2**\n",
    "\n",
    "**CODING:** Markov Chain Monte Carlo (MCMC) is a powerful tool for sampling the posterior distribution of complicated models.  The best way to learn how to implement this is through an example,.  In this problem, you will redo parts of HW6 Problem 2) using the Metropolis-Hastings MCMC algorithm.\n",
    "\n",
    "Recall that we were tasked to model the relation between the number of satellites that reenter the Earth $N_{\\mathrm{reentry}}$ and the average number of sunspots $N_{\\mathrm{sunspot}}$ in a given year.  The data are provided in `ReentryData.dat`.  We used the following model:\n",
    "$$\n",
    "  N_{\\text{reentry}} = a + b N_{\\text{sunspot}}\n",
    "$$\n",
    "where $a$ and $b$ are the fitting parameters.  Using the analytic solution to the MLE, we saw that the posterior distribution is characterized by the means and covariance matrix given by:\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\left( \\begin{array}[r] ~ a \\\\ b \\end{array} \\right)\n",
    "    &=\n",
    "    \\left( \\begin{array}[r] ~ 13.11 \\\\ 0.110 \\end{array} \\right) &\n",
    "    \\Sigma &=\n",
    "    \\left( \\begin{array}[rr] ~ 1.84 & -0.0141 \\\\ -0.0141 & 0.000169 \\end{array} \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "  \n",
    "\n",
    "a) (8 pts) Construct a Markov Chain as follows:\n",
    "   * Initialization:  Start with the best-fit parameters $\\vec{x}_{\\mathrm{old}} = (13.11~0.110)$.  Calculate the value of the likelihood $\\mathscr{L}(\\vec{x}_{\\mathrm{old}})$ at this point.  The step sizes $\\delta\\vec{x}$ must be chosen appropriately such that \n",
    "    \n",
    "   * For each iteration:\n",
    "     * Generate a candidate random step from $\\vec{x}_{\\mathrm{old}}$ by drawing a pair of random numbers $\\vec{r}$ from a normal distribution $\\mathscr{N}(0, \\delta\\vec{x})$.  Your candidate point is $\\vec{x}_{\\mathrm{new}} = \\vec{x}_{\\mathrm{old}} + \\vec{r}$.\n",
    "     * Calculate the ratio $R = \\mathscr{L}(\\vec{x}_{\\mathrm{new}})/\\mathscr{L}(\\vec{x}_{\\mathrm{old}})$.\n",
    "     * Determine whether to accept or reject the candidate step:\n",
    "       - If $R \\geq 1$, take the proposal step (accept).\n",
    "       - else if $R < 1$, then draw a random number $U$ from a uniform distribution between 0 and 1.\n",
    "         * If $U < R$, take the proposal step (accept).\n",
    "         * else if $U \\geq R$, do not take the step (reject).\n",
    "         \n",
    "   Do $10^5$ iterations and choose $\\delta\\vec{x}$ such that $\\sim 50\\%$ ($30-70\\%$) of the candidate steps are accepted.  The output should be a Markov chain (list) of accepted steps $\\{\\vec{x}\\}$.\n",
    "    \n",
    "b) (4 pts) Using the Markov chain from above, calculate the sample means $(\\bar{a}~\\bar{b})$ and covariance matrix, and check that the values are nearly identical to those from the analytic MLE.\n",
    "    \n",
    "c) (3 pts) Install the plotting package \\texttt{corner} in your Anaconda installation.\n",
    "    \n",
    "       conda install corner\n",
    "    \n",
    "   If you run into problems, see:\n",
    "\n",
    "   http://corner.readthedocs.io/en/latest/install.html\n",
    "    \n",
    "   This package allows you to easily visualize the variance and covariance of an MCMC chain.  A quick-start guide can be found here:\n",
    "\n",
    "   http://corner.readthedocs.io/en/latest/pages/quickstart.html\n",
    "\n",
    "   Use this package to visualize the Markov chain, which is just a sampling of the bivariate gaussian characterized by the means and covariance matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf4c9d3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a70d95dc5abd2090f0ad1838ead058fc",
     "grade": false,
     "grade_id": "cell-b20a447acba1e8b7",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Problem 2a\n",
    "\n",
    "def read_sat_data():\n",
    "    \"\"\"Read the satellite and sunspot data and convert sunspots to mean number per year.\n",
    "    \n",
    "    Returns n_sunspots, n_satellites as numpy arrays.\n",
    "    \"\"\"\n",
    "    # Hints:\n",
    "    # 1. Remember to limit the range to the years with data for both sunspots and satellites.\n",
    "    # 2. Feel free to copy the code from the HW6 solution set.\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def sat_likelihood(data, theta):\n",
    "    \"\"\"Compute the likelihood of our data given a set of parameters theta.\n",
    "    \n",
    "    In our case, data is a tuple of numpy arrays: (n_sunspots, n_reentries) and theta is the tuple (a,b).\n",
    "\n",
    "    The likelihood is a Gaussian, assuming the uncertainty in n_reentries is sqrt(n_reentries).\n",
    "    And note that since only relative likelihoods for different choices of theta are relevant, \n",
    "    you can ignore any constant factors that are independent of theta.\n",
    "    \n",
    "    Returns the likelihood for this choice of theta.\n",
    "    \"\"\"\n",
    "    # Hint: This function will be called A LOT during the chain.\n",
    "    #       You really want to avoid having any loops in this function.\n",
    "    #       Use numpy array math and things like np.sum to avoid explicit loops.\n",
    "    #       If you don't know how to do this, you might want to look at how similar \n",
    "    #       functions were implemented in past solution sets.\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b5880",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93721b31180f91b9dba50c5e4434548a",
     "grade": true,
     "grade_id": "cell-2499fb2af20e4364",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "n_sunspots, n_reentries = read_sat_data()\n",
    "\n",
    "print('n_sunspots = ',n_sunspots)\n",
    "print('n_reentries = ',n_reentries)\n",
    "print('len = ',len(n_sunspots),len(n_reentries))\n",
    "\n",
    "# Make sure the data are clipped to the same time period.\n",
    "assert len(n_sunspots) == len(n_reentries)\n",
    "\n",
    "# Make sure we convert to numpy arrays if necessary.\n",
    "assert type(n_sunspots) == np.ndarray\n",
    "assert type(n_reentries) == np.ndarray\n",
    "\n",
    "# Check our likelihood function\n",
    "data = (n_sunspots, n_reentries)\n",
    "mle_theta = (13.11, 0.110)  # This is approximately the MLE solution from HW6.\n",
    "print('Likelihood at MLE solution = ',sat_likelihood(data, mle_theta))\n",
    "\n",
    "# This is expected to be the maximum likelihood.  Make sure it is a peak.\n",
    "print('Likelihood at some other nearby locations:')\n",
    "for theta in [ (13.05, 0.11), (13.15, 0.11), (13.11, 0.105), (13.11, 0.115)]:\n",
    "    print('   L({}) = {}'.format(theta, sat_likelihood(data, theta)))\n",
    "    assert sat_likelihood(data, theta) < sat_likelihood(data, mle_theta)\n",
    "\n",
    "# Finally, make sure our likelihood function is fast enough to run many thousands of times in the MCMC.\n",
    "t0 = time.time()\n",
    "for i in range(100):\n",
    "    theta = np.random.random(2) * 10\n",
    "    sat_likelihood(data,theta)  # ignore return value\n",
    "t1 = time.time()\n",
    "print('time to run sat_likelihood 100 times = ',t1-t0)\n",
    "\n",
    "t2 = time.time()\n",
    "for i in range(10000):\n",
    "    theta = np.random.random(2) * 100\n",
    "    sat_likelihood(data,theta)  # ignore return value\n",
    "t3 = time.time()\n",
    "print('time to run sat_likelihood 10,000 times = ',t3-t2)\n",
    "assert t3-t2 < 5\n",
    "# If this is more than 5 seconds, you need to work on speeding it up.\n",
    "# Note: for the official solution, this takes under 0.1 second on a modern laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a02514d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f9884713a46924bfbc7348ec3f4a9fb",
     "grade": false,
     "grade_id": "cell-80e0c612f339be9e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Aside:** *Quick overview of Python Classes*\n",
    "\n",
    "Those of you who have used Python classes before, feel free to skip this section.  For the rest of you, this should hopefully give you the basics of what you need to know about classes to complete this assignment.\n",
    "\n",
    "A class (in any object-oriented language, not just Python) is a data structure that holds some combination of data, typically stored as attributes, along with some functions that can act on those data.\n",
    "\n",
    "One class you are probably already somewhat familiar with in Python (although you may not have thought of it as a class) is a list.  Every list you make (e.g. `l1 = [1,2,3]`) is an instance of the native Python class `list`.  You can access the class name of any object in Python using a special \"dunder\" (short for double underscore) attribute `__class__`.  Similarly, you can any object's doc string using `__doc__`:\n",
    "\n",
    "    >>> l1 = [1,2,3]\n",
    "    >>> print(l1.__class__)\n",
    "    <class 'list'>\n",
    "    >>> print(l1.__doc__)\n",
    "    Built-in mutable sequence.\n",
    "\n",
    "    If no argument is given, the constructor creates a new empty list.\n",
    "    The argument must be an iterable if specified.\n",
    "\n",
    "The more interesting attributes are functions, which can act on the object's data.  These are called methods in the standard terminology, to distinguish from free functions, not embedded in a class.  Some methods of `list` that you might be familiar with include `sort`, `append`, `reverse`, and `clear`:\n",
    "\n",
    "    >>> l2 = [5, 1, 12, 8, 0]\n",
    "    >>> l2.sort()\n",
    "    >>> print(l2)\n",
    "    [0, 1, 5, 8, 12]\n",
    "    >>> l2.append(6)\n",
    "    >>> print(l2)\n",
    "    [0, 1, 5, 8, 12, 6]\n",
    "    >>> l2.reverse()\n",
    "    >>> print(l2)\n",
    "    [6, 12, 8, 5, 1, 0]\n",
    "    >>> l2.clear()\n",
    "    >>> print(l2)\n",
    "    []\n",
    "\n",
    "Python makes it easy to define your own classes, which we will do for this problem.  We'll define a class called `MCMC`, which we'll use to keep track of the samples of the Markhov Chain as we run through a bunch of steps.  We will make an instance of this class according to a number of parameters:\n",
    "\n",
    "    sat_mcmc = MCMC(sat_likelihood, data, theta, step_size, names)\n",
    "    \n",
    "This looks a bit like a function call, but the right hand side is the name of the class, followed by the parameters we'll use when making the class.  The initialization is actually done by a method called `__init__`, which is defined in the class definition.  More details on what all these parameters mean are given in the doc string below.\n",
    "\n",
    "The return value, which we named `sat_mcmc` is an instance of the `MCMC` class, which we can use to run the chain by calling various methods:\n",
    "\n",
    "    sat_mcmc.burn(100)\n",
    "    sat_mcmc.run(10000)\n",
    "    \n",
    "and then make some visualizations to see how the run is progressing:\n",
    "\n",
    "    sat_mcmc.plot_samples()\n",
    "    sat_mcmc.plot_hist()\n",
    "\n",
    "These methods are all already defined for you, since they are fairly straightforward.  The real meat of the calculation is in the `step` method, which carries out one step of the chain.  This method you will need to write yourself.  \n",
    "\n",
    "You'll note that the first argument of each method defined below is a special parameter called `self`.  This is the name of the instance that was used to call the method.  E.g. when you call `sat_mcmc.burn(100)`, this turns into a call to `MCMC.burn` with the first parameter being `self=sat_mcmc` and the second parameter being `nburn=100`.  This lets you access the stored attributes of current instance from inside the function definition (e.g. those that are set in the `__init__` like `self.nparams` or `self.step_size`) or call other methods (e.g. `self.step()`).\n",
    "\n",
    "When writing the definition of `MCMC.step`, you'll need to use some of the parameters that are saved for you in the initialization, and also update some state parameters to effect a single Metropolis Hastings step.  You can write to any saved attribute just like how you write to a normal variable.  For instance,\n",
    "\n",
    "    self.naccept += 1\n",
    "    \n",
    "will add 1 to the `naccept` attribute of the current instance, which in our case would be `sat_mcmc`.\n",
    "\n",
    "For another overview of Python classes, here is a pretty good one:\n",
    "\n",
    "https://www.dataquest.io/blog/using-classes-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50753409",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b99162143acea85a3fffac6340f8a6fb",
     "grade": false,
     "grade_id": "cell-e6b0638b3785a51d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Problem 2a (continued)\n",
    "class MCMC:\n",
    "    \"\"\"Class that can run an MCMC chain using the Metropolis Hastings algorithm\n",
    "\n",
    "    This class is based heavily on the \"Trivial Metropolis Hastings\" algorithm discussed in lecture.\n",
    "    If you haven't used classes before, you can think of it as just a way of organizing the variables\n",
    "    and functions related to the MCMC operation.\n",
    "\n",
    "    You use it by creating an instance of the class as follows:\n",
    "\n",
    "        mcmc = MCMC(likelihood, data, theta, step_size)\n",
    "\n",
    "    The parameters here are:\n",
    "\n",
    "        likelihood is a function returning the likelihood p(data|theta), which needs to be\n",
    "            defined outside the class.  The function should take two variables (data, theta) and \n",
    "            return a single value p(data | theta).\n",
    "\n",
    "        data is the input data in whatever form the likelihood function is expecting it.  \n",
    "            This is fixed over the course of running an MCMC chain.\n",
    "\n",
    "        theta is a list or array with the starting parameter values for the chain.\n",
    "\n",
    "        step_size is a list or array with the step size in each dimension of theta.\n",
    "\n",
    "\n",
    "    Then once you have an MCMC object, you can use it by running the following functions:\n",
    "\n",
    "        mcmc.burn(nburn) runs the chain for nburn steps, but doesn't save the values.\n",
    "\n",
    "        mcmc.run(nsteps) runs the chain for nsteps steps, saving the results.\n",
    "\n",
    "        mcmc.accept_fraction() returns what fraction of the candidate steps were taken.\n",
    "\n",
    "        mcmc.get_samples() returns the sampled theta values as a 2d numpy array.\n",
    "\n",
    "\n",
    "    There are also simple two plotting functions that you can use to look at the behavior of the chain.\n",
    "\n",
    "        mcmc.plot_hist() plots a histogram of the sample values for each paramter.  As the chain\n",
    "            runs for more steps, this should get smoother.\n",
    "        \n",
    "        mcmc.plot_samples() plots the sample values over the course of the chain.  If the burn in is\n",
    "            too short, it should be evident as a feature at the start of these plots.\n",
    "\n",
    "\n",
    "    Finally, there is only one method you need to write yourself.\n",
    "    \n",
    "        mcmc.step() takes a single step of the chain.\n",
    "    \"\"\"\n",
    "    def __init__(self, likelihood, data, theta, step_size, names=None, seed=314159):\n",
    "        self.likelihood = likelihood\n",
    "        self.data = data\n",
    "        self.theta = np.array(theta)\n",
    "        self.nparams = len(theta)\n",
    "        self.step_size = np.array(step_size)\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "        self.naccept = 0\n",
    "        self.current_like = likelihood(self.data, self.theta)\n",
    "        self.samples = []\n",
    "        if names is None:\n",
    "            names = [\"Paramter {:d}\".format(k+1) for k in range(self.nparams)]\n",
    "        self.names = names            \n",
    "\n",
    "    def step(self, save=True):\n",
    "        \"\"\"Take a single step in the chain\"\"\"\n",
    "        # 1. Calculate the new theta value.\n",
    "        # 2. Calculate the likelihood for that theta.       \n",
    "        # 3. Decide whether or not to take the step.\n",
    "        # 4. If taking the step, update self.current_like and self.theta.\n",
    "        # 5. If save==True, add the sample to self.samples and maybe add 1 to self.naccept.\n",
    "        \n",
    "        # Hint: For the random numbers use the stored RandomState, not np.random functions.\n",
    "        #       Otherwise the comments below about how your results should look might not make much sense.\n",
    "        #       E.g. self.rng.normal, not np.random.normal.\n",
    "        #            and self.rng.uniform, not np.random.uniform, etc.\n",
    "        #       In general, using a well-defined random seed will help keep things repeatable\n",
    "        #       while still have pseudo-random behavior in your programs.\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def burn(self, nburn):\n",
    "        \"\"\"Take nburn steps, but don't save the results\"\"\"\n",
    "        for i in range(nburn):\n",
    "            self.step(save=False)\n",
    "\n",
    "    def run(self, nsteps):\n",
    "        \"\"\"Take nsteps steps\"\"\"\n",
    "        for i in range(nsteps):\n",
    "            self.step()\n",
    "\n",
    "    def accept_fraction(self):\n",
    "        \"\"\"Returns the fraction of candidate steps that were accpeted so far.\"\"\"\n",
    "        if len(self.samples) > 0:\n",
    "            return float(self.naccept) / len(self.samples)\n",
    "        else:\n",
    "            return 0.\n",
    "        \n",
    "    def clear(self, step_size=None, theta=None):\n",
    "        \"\"\"Clear the list of stored samples from any runs so far.\n",
    "        \n",
    "        You can also change the step_size to a new value at this time by giving a step_size as an\n",
    "        optional parameter value.\n",
    "        \n",
    "        In addition, you can reset theta to a new starting value if theta is not None.\n",
    "        \"\"\"\n",
    "        if step_size is not None:\n",
    "            assert len(step_size) == self.nparams\n",
    "            self.step_size = np.array(step_size)\n",
    "        if theta is not None:\n",
    "            assert len(theta) == self.nparams\n",
    "            self.theta = np.array(theta)\n",
    "            self.current_like = self.likelihood(self.data, self.theta)\n",
    "        self.samples = []\n",
    "        self.naccept = 0\n",
    "        \n",
    "    def get_samples(self):\n",
    "        \"\"\"Return the sampled theta values at each step in the chain as a 2d numpy array.\"\"\"\n",
    "        return np.array(self.samples)\n",
    "        \n",
    "    def plot_hist(self):\n",
    "        \"\"\"Plot a histogram of the sample values for each parameter in the theta vector.\"\"\"\n",
    "        all_samples = self.get_samples()\n",
    "        for k in range(self.nparams):\n",
    "            theta_k = all_samples[:,k]\n",
    "            plt.hist(theta_k, bins=100)\n",
    "            plt.xlabel(self.names[k])\n",
    "            plt.ylabel(\"N Samples\")\n",
    "            plt.show()\n",
    "        \n",
    "    def plot_samples(self):\n",
    "        \"\"\"Plot the sample values over the course of the chain so far.\"\"\"\n",
    "        all_samples = self.get_samples()\n",
    "        for k in range(self.nparams):\n",
    "            theta_k = all_samples[:,k]\n",
    "            plt.plot(range(len(theta_k)), theta_k)\n",
    "            plt.xlabel(\"Step in chain\")\n",
    "            plt.ylabel(self.names[k])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f88ba3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d5c7e53358db71fa97a4cf790daa6d5",
     "grade": true,
     "grade_id": "cell-3ba647005d2db8eb",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# It's helpful to start an MCMC at a good initial guess.  The worse the initial guess, the more\n",
    "# \"burn in\" is required to produce a good chain.  Starting at the MLE solution means that we shouldn't\n",
    "# need much burn in, but we'll do a little bit anyway.\n",
    "theta = mle_theta\n",
    "\n",
    "# Here, we'll run this with a poor choice of step size to show what that looks like.\n",
    "# In the next cell down, you can play around with modifying this to produce better results.\n",
    "step_size = (0.1, 0.1)\n",
    "\n",
    "# Make the mcmc object with the satellite likelihood function\n",
    "sat_mcmc = MCMC(sat_likelihood, data, theta, step_size, names=('$a$','$b$'))\n",
    "\n",
    "# Run the burn-in.  \n",
    "# This is more important for complicated models where you may not really know a good starting point.\n",
    "# In that case, a rule of thumb is to burn in for about 10% of the total length of the MCMC run.\n",
    "# Here, we don't need to be so conservative. \n",
    "# Using 100 burn in steps is plenty to get the chain to forget precisely where it started.\n",
    "sat_mcmc.burn(100)\n",
    "\n",
    "# In the next section, you will pick a good choice for the number of steps.  Here we do 10000.\n",
    "sat_mcmc.run(10000)\n",
    "\n",
    "# Plot the samples to check the burn in and sample size.\n",
    "sat_mcmc.plot_samples()\n",
    "\n",
    "# Plot histograms of the parameter values to see if they look converged.\n",
    "sat_mcmc.plot_hist()\n",
    "\n",
    "print('After running for 1000 steps:')\n",
    "print('Acceptance rate is ', sat_mcmc.accept_fraction())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f50143e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "021e7714eae6fd6953a2a46947077d94",
     "grade": false,
     "grade_id": "cell-c9c0460e2456b568",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Some things to notice about the above plots.\n",
    "\n",
    "1. The histogram of b looks reasonably Gaussian (albeit noisy).  This is good.\n",
    "   It means the chain is well sampling the posterior distribution of b around the maximum likelihood value.\n",
    "2. The samples for b versus step number looks extremely noisy.  This is also good.\n",
    "   You want the parameter values from one step to the next to jump around a lot relative to the full range of the\n",
    "   distribution.\n",
    "3. The histogram of a is not very Gaussian.  It has two peaks and is clearly missing an important part\n",
    "   of the distribution near the MLE solution.  This means that the chain has not \"converged\".  It may mean that you\n",
    "   need to let it run longer, or you may need to adjust the step size.  (Or both.)\n",
    "4. The samples for a are very correlated from one step to the next.  The a values only slowly meander through the\n",
    "   allowed space.  The chain happens to have spent most of the time in two portions of the full range, explaining\n",
    "   why we saw two peaks in the final a histogram.  This is typically a sign that the step size for a is too small.\n",
    "5. The acceptance rate is only about 0.1.  This is very low.  It means that 9/10 of the candidate steps are rejected.\n",
    "   This is typically a sign that one or both of the step sizes is too large.  The chain keeps trying to jump too far\n",
    "   away from the peak, and the step is rejected.\n",
    "   \n",
    "Now you have a chance to play around with the two step size parameters to try to pick something more reasonable.\n",
    "Your goals are:\n",
    "\n",
    "1. Get the histograms to look reasonably Gaussian (at least single peaked).\n",
    "2. Get the samples vs step number to look very noisy (not meandering for either one)\n",
    "3. Get the acceptance rate near 0.5\n",
    "\n",
    "Once you've done that, feel free to increase the number of samples in the chain.  Don't have it run for more than about 1 minute, but generally the more samples you have, the better the final statistics and contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c83aed4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bc4d5e2347c6a0c7dcd6c6c46084de0",
     "grade": false,
     "grade_id": "cell-e0f6441d951bd69d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Problem 2a (continued)\n",
    "def sat_step_size():\n",
    "    \"\"\"Return your choice of step size in (a,b) as a tuple.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def sat_nsteps():\n",
    "    \"\"\"Return how many steps to run\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd78879",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "604e8387e6cb00989817f221a1ff170f",
     "grade": true,
     "grade_id": "cell-907f069ece5e962c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "theta = mle_theta\n",
    "\n",
    "sat_mcmc = MCMC(sat_likelihood, data, mle_theta, sat_step_size(), names=('$a$','$b$'))\n",
    "\n",
    "sat_mcmc.burn(100)\n",
    "\n",
    "t0 = time.time()\n",
    "sat_mcmc.run(sat_nsteps())\n",
    "t1 = time.time()\n",
    "\n",
    "sat_mcmc.plot_samples()\n",
    "\n",
    "sat_mcmc.plot_hist()\n",
    "\n",
    "print('After running for {} steps:'.format(sat_nsteps()))\n",
    "print('Acceptance rate is ', sat_mcmc.accept_fraction())\n",
    "print('Time to run chain is {} seconds'.format(t1-t0))\n",
    "\n",
    "assert 0.3 < sat_mcmc.accept_fraction() < 0.7    # Adjust step sizes if this fails.\n",
    "assert t1-t0 < 120   # Make sure it is < 60 on your system.  \n",
    "                     # If it takes longer than 2 min on the TA's computer, we may dock points.\n",
    "                     # (The official solution gets quite good statistics in only a couple seconds.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55255a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55abec1c81a95145a6c24586018dc8b9",
     "grade": false,
     "grade_id": "cell-08ab7807e5ebc895",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Problem 2b\n",
    "def calculate_mean(mcmc):\n",
    "    \"\"\"Calculate the mean of each parameter according to the samples in the MCMC object.\n",
    "\n",
    "    Returns the mean values as a numpy array.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def calculate_cov(mcmc):\n",
    "    \"\"\"Calculate the covariance matrix of the parameters according to the samples in the MCMC object.\n",
    "\n",
    "    Returns the covariance matrix as a 2d numpy array.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccaa1b9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7d93f253c61635a3bbfcd8ff16ad15b",
     "grade": true,
     "grade_id": "cell-91558298b26bef29",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Now that we think we have a good chain and that it is converged, we can compute the mean and covariance\n",
    "# of the parameters.\n",
    "mean = calculate_mean(sat_mcmc)\n",
    "cov = calculate_cov(sat_mcmc)\n",
    "\n",
    "print('Mean values of (a,b) = ', mean)\n",
    "print('Uncertainties of (a,b) = ', np.sqrt(cov.diagonal()))\n",
    "print('Covariance matrix = \\n', cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d305a797",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01c1087b360755f8103952a24456a44b",
     "grade": true,
     "grade_id": "cell-2498d25def3114a9",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import corner\n",
    "# Note: You will need to install this.  See http://corner.readthedocs.io/en/latest/install.html\n",
    "\n",
    "# Problem 2c\n",
    "def plot_corner(mcmc):\n",
    "    \"\"\"Make a corner plot for the parameters a and b with contours corresponding to the same\n",
    "    delta chisq contours we drew in homework 4.\n",
    "    \"\"\"\n",
    "    # Hint: Use the corner.corner function\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "plot_corner(sat_mcmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a11a2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ecf0d26b441c31673b28603ca9a4544",
     "grade": false,
     "grade_id": "cell-09b8326e3ac27cc1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Problem 3**\n",
    "\n",
    "**CODING, EXTRA CREDIT** (3 pts) Repeat Problem 2 for the non-linear regression problem in Problem 1.  \n",
    "Specifically, generate a 6-parameter Markov Chain, solve for the means and covariance matrix, \n",
    "and plot the posterior distributions with $\\texttt{corner}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4b5aa0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfc911548f57dbe1dafb2206a7e82da8",
     "grade": true,
     "grade_id": "cell-781817231b2490a9",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Problem 3  (EXTRA CREDIT)\n",
    "\n",
    "# Hint: With more parameters, the optimal acceptance fraction goes down. \n",
    "#       More or less 1/Nparams is good.  So about 0.16 in this case.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deece671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
